========================================================================================================================================
							Bayes theorem
========================================================================================================================================

Probability:
Random experiment - An experiment in which the outcome is not known certainity.
                    That is output of a random experiment cannot be predicted with certainity.
Sample space - Universal set that consists of all possible outcomes of an experiment and individual outcome are called elementary events.
Event - A subset of sample space and probability is usually calculated with respect to an event.
    ex: - Number of cancellation of orders
          Number of fraud credit cards transaction

3 types: Marginal, Joint and Conditional

Naive Bayes theorem :
- It is also known as binary classifier or probability classifier
- Widely used in text categorization
--> Supervised Algorithm
--> Bayes theorem
--> Native assumption (Occurence of features are independent)
Bayes theorem formula :
    P(A)
    P(B)
    P(A/B)= P(A and B)/P(B) ..(1)
    P(B/A)= P(A and B)/P(A) 
    P(A and B)= P(B/A).P(A).. in(1)
    so, P(A/B)= [P(B/A).P(A)] /P(B) .. Derived equation 

=====================================================================================================================================
					Random variable, Covariance, Correlation
=====================================================================================================================================
Parameters of diagnostic analytics
- Correlation
- Covariance
- Outliers

For checking similarities between random variables we use covaraiance and correlation.
covaraiance indicates the direction of linear relationship between variables.
correlation indicates strength and direction of linear relationship between 2 variables.
Correlation is a function of the covaraiance.

Linear relationshipbetween two random variables:
	- Correlation value r-strength
	- sign indicates direction : '+' or '-'
Different correlation coefficients:
	- Pearson correlation coefficient
	- Spearman's rank correlation 
range:[-1 ... 0 ... +1]

Pearson correlation (R):    sum[(x-mean(x))*(y-mean(y))]
			R = ------------------------------------------
			    sqrt[(sum[(x-mean(x))^2)*((y-mean(y))^2)]]

Spearman's rank correlation (P):         [6*(sum[Rank(x)-Rank(x)])]
				 P = 1 - ---------------------------         (If any data is similar then consider the average of it)
                                         N*((N^2)-1)

Covariance : sum((x-mean(x))*(y-mean(y)))/n	  ,Population Covariance
	     sum((x-mean(x))*(y-mean(y)))/n-1     ,Sample Covariance
=====================================================================================================================================
					Statistic measures - Mean,Median,Mode ; StdDev, Variance
=====================================================================================================================================

<DataSet1>=[d1,d2,d3]
<DataSet2>=[d1,d2,d3,d4]
Measures : 
	1.Central tendency : Mean,Mode and Median
		Mean - Sum of values/Number of values mean of <DataSet1>=d1+d2+d3/3 and mean of <DataSet2>=d1+d2+d3+d4/4
  					(d1+d2....+dn)
				mean = ----------------
					      n	

		Mode - Most common or repeated value 
		Median - Sort and pick the middle value median of <DataSet1>=d2 ,median of <DataSet2>=(d2+d3)/2
				
					   d(n/2)+d((n/2)+1)
				median 	= -------------------  , if n is even
					     	2 
					= d((n+1)/2) 		, if n is odd 		

	2.Dispersion : Range, Standard Deviation and variance
		Range - Difference between Min and Max of dataset. 	
			Range of <DataSet1>=max(<DataSet1>)-min(<DataSet2>) ; 
			Range of <DataSet2>=max(<DataSet2>)-min(<DataSet2>)
				Range = max(d)-min(d)

		Standard Deviation- Sqareroot of Sum of square of difference of dataset values and mean of dataset /One less count of number of dataset values.
			SD=sqrt(sum(square (<DataSet1/2>-mean(<DataSet1/2>)) ))/(N-1))
				
				           [ sum(square(d-datapoints-mean(d)))]
				SD   = sqrt|----------------------------------|
					   [	        n-1		      ]
		variance - Sum of square of difference of dataset values and mean of dataset /One less count of number of dataset values or Sqaure of Standard deviation.
			V =sum(square ( <DataSet1/2> - mean(<DataSet1/2>) ) )/(N-1)
				          [ sum(square(d-datapoints-mean(d)))]
				V=SD*SD = |----------------------------------|
				          [	        n-1		     ]

=====================================================================================================================================
						Probability distribution					
=====================================================================================================================================

Random variable : Function that maps every outcome in the sample space to a real number it can be both continous and discrete.
Discrete random variable - Random variable can assume only finite or countably infinite set of values. 
				Described using PMF(Probability mass function) 
						CDF(Cumulative distribution function)
Continous random variable - Random variable can take value from an infinite set of values. 
				Described using PDF(Probabiliyty Distribution function) 
						CDF(Cumulative distribution function)

Probability distribution :
	1. Discrete distribution: Binomial, Poission, Geometric
	2. Continous distribution: Uniform, Exponential, Normal

Discrete Probability functions:
	Binomial distribution -
		PMF = P(x)= nCx*(p^x)*(q^(n-x))=
		CDF = F(r)=sum((n/x)*(p^x)*(q^(n-x)=
	Poission distribution -
		PMF = P(X=x)=(e^(-lambda))*(lambda^x)/x!

	PDF= f(x)=[1/sqrt(2*pi*square(sigma))]*e^(-[square(x-rho)]/(2*square(sigma)))
	Geometric distribution -
		P(X=k)=[(1−p)^(k−1)]*p
		
varaince

Normal Distribution 
	mean(x)=(1/n)*sum(x,i-n)
	varaince=(1/n)*sum(x-mean(x),i-n)^2
---------------------------------------------------------

Discrete distribution - Binomial, Poissons, Geometric
Continous distribution - Uniform , Exponential, Normal
For Discrete random variable : PMF and CDF
For Continous random variable : PDF and CDF
Binomial
	PMF
	CDF
Poission
	PMF
Normal DistributionND
	PDF
	
PMF - sns.histplot(beml_gain,kde=False,discrete=True) , 
PDF - sns.ecdfplot(beml_gain,kde=True) , 
CDF - sns.ecdfplot(beml_gain)
--------------------------------------------------------

=====================================================================================================================================
						Hypothesis testing					
=====================================================================================================================================

- It is an example of Infrential statistics,
- It is a claim
- The test is to retain or reject a null hypothesis
- 2 complementary statements :
	Null Hypothesis - An existing belief
	Alternate Hypothesis - It is intended to establish a new evidance.
- 2 tests :
	parametric test : It is describe by population parameters.Example- Ztest,Ttest(1Sample, 2 Sample,PairedSample and ENOVA)
	NonParametric : It use data to comment on calim .Example(Chi sqaure)

Steps to perform hypothesis testing :
	1. Define Null and Alternate hypothesis.It is described by populatuion parameters.
	2. Identify the test statistics for validating the null hypothesis.
	3. declare the criteria for retaining and rejecting the null hypothesis.Significance value.
	4. Find Pvalue (conditional probability) which is observed to the test statistics where null hypothesis is true.
	5. Decide whether the claim has to be accepted or rejected.



Infrential Statistics - Process of estimating population parameters(Characters of population : Mean,Median, StdDev etc.. ).
error in estimation of population parameters that is based on sample statistics.
CLL(Central limit theorem) - 

Hypothesis testing 
It is example of infrential statistics.Hypothesis is a claim.
It is either accepted or rejected
Consists of 2 complementary statements:
	Null hypothesis(Ho)
	Alternate hypothesis(Ha)
Types of hypothesis testing:
	Parametric - ZTest,TTest,ANOVA(Analysis of Variance)
	Non Parametric - ChiSquare
Notation :
	rho - Population mean
	sigma - Population  StdDev
	X- sample mean
	S- sample StdDev
	n- sample size

ZTest : Z=(X-rho)/(sigma/sqrt(n))
TTest : 3 types- 1Sample, 2Sample, PairedSample
	population is given but StdDev is not given
1Sample - 1 population mean is given and StdDev is not given
2Sample - Test difference between given 2 population means and StdDev is not given
PairedSample - Before and After estimation

ANOVA(analysis ofvariance) - 
1 way ANOVA - [ Ho : rho1=rho2=rho3 ],[Ha : rho1!=rho2!=rho3 ]
ChiSquare - x^2=sum[((Oi-Ei)^2)/Ei]


=====================================================================================================================================
						Prediction modelling
=====================================================================================================================================

Models,Induction and prediction
Supervised(Supervised learning models) segmentation : Classification and Regression

Model is a simplified representation of reality created to serve a purpose
predictive model is a formula for estimating the unknown value of interest known as the target.

data mining deal with historical data,models - built and tested using events from the past.
Model induction: Creation of model from data
Induction algorith or learner : Procedure that creates the model from the data

Classification segmentation : Decision tree and Logistic regression
Classification problems with binary outcome['+':1 ,'-':0] are called binary classification.P(Y=1)=(e^z)/(1+(e^z))=1/(1+(e^-z))
		z= B0+B1X1+B2X2++BmXm
Classification problems with multiple outcome are called multinomial classification.
Techniques - Logistic regression, Classification trees, Discriminant analysis,Neural network,SVM(Support vector machine)

Classification using Decision trees:
Selecting Information attributes
Visualizing the segmentation
Trees as a set of rules

Entropy-
E(s)-  -sum(Pilog(Pi)) where Pi-proportion value
E(s1)- (-VS1/s)log2(VS1/s)
E(s2)- (-VS2/s)log2(VS2/s)

(Infrential Gain)IG=E(s)-E(s1)-E(s2)