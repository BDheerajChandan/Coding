{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388d1588",
   "metadata": {},
   "source": [
    "# 1. Vectorizaton and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc3bfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Index: {'deep': 1, 'learning': 2, 'i': 3, 'love': 4, 'is': 5, 'amazing': 6}\n",
      "Tokenized & Vectorized: [[3, 4, 1, 2], [1, 2, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Sample text\n",
    "#texts = [\"I love deep learning\", \"Deep learning is amazing\"]\n",
    "texts = [\"I love deep learning\", \"Deep learning is amazing\"]\n",
    "\n",
    "tokenizer = Tokenizer()                 # Create a tokenizer\n",
    "tokenizer.fit_on_texts(texts)           # Fit the tokenizer on the text\n",
    "print(\"Word Index:\", tokenizer.word_index)      # Show word index (each word gets a number)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts) # Convert text to sequences of numbers\n",
    "print(\"Tokenized & Vectorized:\", sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d540d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Index: {'deep': 1, 'learning': 2, 'i': 3, 'love': 4, 'is': 5, 'amazing': 6}\n",
      "Tokenized & Vectorized: [[3, 4, 1, 2], [1, 2, 5, 6]]\n",
      "Padded Sequences:\n",
      " [[3 4 1 2]\n",
      " [1 2 5 6]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Sample text\n",
    "texts = [\"I love deep learning\", \"Deep learning is amazing\"]\n",
    "\n",
    "# Create a tokenizer and fit it on the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Show word index (each word gets a number)\n",
    "print(\"Word Index:\", tokenizer.word_index)\n",
    "\n",
    "# Convert text to sequences of numbers\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "print(\"Tokenized & Vectorized:\", sequences)\n",
    "\n",
    "# Pad sequences to create a uniform input shape\n",
    "padded = pad_sequences(sequences)\n",
    "print(\"Padded Sequences:\\n\", padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c03bc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot Encoded Docs: [[1, 32, 19, 41], [19, 41, 32, 40]]\n",
      "Word Index (Tokenizer): {'deep': 1, 'learning': 2, 'i': 3, 'love': 4, 'is': 5, 'amazing': 6}\n",
      "Tokenized & Vectorized (Tokenizer): [[3, 4, 1, 2], [1, 2, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "# Sample text\n",
    "texts = [\"I love deep learning\", \"Deep learning is amazing\"]\n",
    "\n",
    "# One-Hot Encoding manually (with vocab size)\n",
    "vocab_size = 50  # Choose a vocab size larger than your total unique words\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in texts]\n",
    "print(\"One Hot Encoded Docs:\", encoded_docs)\n",
    "\n",
    "# Using Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "print(\"Word Index (Tokenizer):\", tokenizer.word_index)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "print(\"Tokenized & Vectorized (Tokenizer):\", sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86fd345",
   "metadata": {},
   "source": [
    "# 2. Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f1159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score :  0.1 ; Positive sentiment :  I like action movies\n",
      "Sentiment score :  0.18 ; Positive sentiment :  I like action movies very much\n",
      "Sentiment score :  0.625 ; Positive sentiment :  I love this product, it's amazing!\n",
      "Sentiment score :  0.0 ; Neutral sentiment :   dont known why I feel uncomforatable\n",
      "Sentiment score :  0.0 ; Neutral sentiment :  I watched a movie last night when I was sleepy mood. \n",
      "Sentiment score :  -0.5 ; Negative sentiment :  I feel headache and getting angry soon. \n",
      "Sentiment score :  -0.4 ; Negative sentiment :  I feel irritating, leave me alone\n",
      "Sentiment score :  0.0 ; Neutral sentiment :  Leave me alone else I wil shout on you\n",
      "Sentiment score :  -0.3125 ; Negative sentiment :  Leave me alone else I wil shout on you due to angry.\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Sample text\n",
    "text = [\"I like action movies\",\n",
    "        \"I like action movies very much\",\n",
    "        \"I love this product, it's amazing!\",\n",
    "        \" dont known why I feel uncomforatable\",\n",
    "        \"I watched a movie last night when I was sleepy mood. \",\n",
    "        \"I feel headache and getting angry soon. \",\n",
    "        \"I feel irritating, leave me alone\",\n",
    "        \"Leave me alone else I wil shout on you\",\n",
    "        \"Leave me alone else I wil shout on you due to angry.\"]\n",
    "for i in text:\n",
    "    blob = TextBlob(i)                              # Create a TextBlob object\n",
    "    sentiment = blob.sentiment.polarity             # Get the sentiment polarity (ranges from -1 to 1)\n",
    "    print(\"Sentiment score : \",sentiment,end=\"\")\n",
    "\n",
    "    # Output the sentiment\n",
    "    if sentiment > 0:\n",
    "        print(\" ; Positive sentiment : \",i)\n",
    "    elif sentiment < 0:\n",
    "        print(\" ; Negative sentiment : \",i)\n",
    "    else:\n",
    "        print(\" ; Neutral sentiment : \",i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c658835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from pattern.en import sentiment, lexicon\\n\\n# See number of words in the lexicon\\nprint(len(lexicon))  # Output: ~2900 words\\n\\n# Print a few words and their polarity\\nfor word in list(lexicon.keys())[:10]:\\n    print(word, sentiment(word))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from pattern.en import sentiment, lexicon\n",
    "\n",
    "# See number of words in the lexicon\n",
    "print(len(lexicon))  # Output: ~2900 words\n",
    "\n",
    "# Print a few words and their polarity\n",
    "for word in list(lexicon.keys())[:10]:\n",
    "    print(word, sentiment(word))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea59d1",
   "metadata": {},
   "source": [
    "# 3. Text clasifiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32e12aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAfter performing Sentiment Analysis, if you use the labeled data (like positive, negative, neutral) to train a \\nmachine learning model that can predict the sentiment of new, unseen text, you're performing: âœ… Text Classification.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "After performing Sentiment Analysis, if you use the labeled data (like positive, negative, neutral) to train a \n",
    "machine learning model that can predict the sentiment of new, unseen text, you're performing: âœ… Text Classification.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6759de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score :  0.1 ; Positive sentiment :  I like action movies\n",
      "Sentiment score :  0.625 ; Positive sentiment :  I love this product, it's amazing!\n",
      "Sentiment score :  0.0 ; Neutral sentiment :  I watched a movie last night when I was sleepy mood. \n",
      "Sentiment score :  -0.5 ; Negative sentiment :  I feel headache and getting angry soon. \n",
      "Sentiment score :  0.0 ; Neutral sentiment :  Leave me alone else I wil shout on you\n",
      "Sentiment score :  -0.3125 ; Negative sentiment :  Leave me alone else I wil shout on you due to angry.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'I like action movies': 'Positive sentiment',\n",
       " \"I love this product, it's amazing!\": 'Positive sentiment',\n",
       " 'I watched a movie last night when I was sleepy mood. ': 'Neutral sentiment',\n",
       " 'I feel headache and getting angry soon. ': 'Negative sentiment',\n",
       " 'Leave me alone else I wil shout on you': 'Neutral sentiment',\n",
       " 'Leave me alone else I wil shout on you due to angry.': 'Negative sentiment'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Sample text\n",
    "data=dict()\n",
    "text = [\"I like action movies\",\n",
    "        \"I love this product, it's amazing!\",\n",
    "        \"I watched a movie last night when I was sleepy mood. \",\n",
    "        \"I feel headache and getting angry soon. \",\n",
    "        \"Leave me alone else I wil shout on you\",\n",
    "        \"Leave me alone else I wil shout on you due to angry.\"]\n",
    "for i in text:\n",
    "    blob = TextBlob(i)                              # Create a TextBlob object\n",
    "    sentiment = blob.sentiment.polarity             # Get the sentiment polarity (ranges from -1 to 1)\n",
    "    print(\"Sentiment score : \",sentiment,end=\"\")\n",
    "    \n",
    "    # Output the sentiment\n",
    "    if sentiment > 0:\n",
    "        print(\" ; Positive sentiment : \",i)\n",
    "        data.update({i:\"Positive sentiment\"})\n",
    "    elif sentiment < 0:\n",
    "        print(\" ; Negative sentiment : \",i)\n",
    "        data.update({i:\"Negative sentiment\"})\n",
    "    else:\n",
    "        print(\" ; Neutral sentiment : \",i)\n",
    "        data.update({i:\"Neutral sentiment\"})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a43589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was amazing  :  Positive sentiment\n",
      "Terrible service  :  Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Sample data\n",
    "texts = list(data.keys())       #[\"I love this! amazing\", \"I hate this!\", \"Best experience\", \"Worst experience\"]\n",
    "labels = list(data.values())    #[\"positive\", \"negative\", \"positive\", \"negative\"]\n",
    "\n",
    "vectorizer = CountVectorizer()      # Convert text to numbers\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "model = MultinomialNB()             # Load model\n",
    "model.fit(X, labels)                # Train model\n",
    "\n",
    "test = [\"It was amazing\", \"Terrible service\"]\n",
    "X_test = vectorizer.transform(test)                 # Vectorising\n",
    "for i,j in zip(test,model.predict(X_test)):         # Predict\n",
    "    print(i,\" : \",j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f28fbc",
   "metadata": {},
   "source": [
    "# 4. Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186635e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# English to Hindi model\n",
    "model_name = 'Helsinki-NLP/opus-mt-en-hi'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Translate\n",
    "text = \"How are you? Are u fine ?\"\n",
    "tokens = tokenizer.prepare_seq2seq_batch([text], return_tensors=\"pt\")\n",
    "translation = model.generate(**tokens)\n",
    "translated_text = tokenizer.decode(translation[0], skip_special_tokens=True)\n",
    "\n",
    "print(translated_text)  # Output: à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197c94b4",
   "metadata": {},
   "source": [
    "# 6. Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d3a320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google => ORG\n",
      "Larry Page => PERSON\n",
      "Sergey Brin => PERSON\n",
      "Stanford University => ORG\n",
      "1998 => DATE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")      # Load English model\n",
    "\n",
    "# Input text\n",
    "text = \"Google was founded by Larry Page and Sergey Brin at Stanford University in 1998.\"\n",
    "\n",
    "doc = nlp(text)                         # Process text\n",
    "\n",
    "for ent in doc.ents:                    # Print named entities\n",
    "    print(ent.text, \"=>\", ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4486efe",
   "metadata": {},
   "source": [
    "# 7. Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95657457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained summarizer\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# Long text to summarize\n",
    "text = \"\"\"Python is a high-level, interpreted programming language known for its simplicity and readability. \n",
    "It supports multiple programming paradigms and has a large standard library. \n",
    "Python is widely used in data science, machine learning, web development, and automation.\"\"\"\n",
    "\n",
    "# Get summary\n",
    "summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c148baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
      "Python is widely used in data science, machine learning, web development, and automation.\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "text = \"\"\"Python is a high-level, interpreted programming language known for its simplicity and readability. \n",
    "It supports multiple programming paradigms and has a large standard library. \n",
    "Python is widely used in data science, machine learning, web development, and automation.\"\"\"\n",
    "\n",
    "parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "summarizer = LsaSummarizer()\n",
    "summary = summarizer(parser.document, 2)  # 2 sentences\n",
    "\n",
    "\n",
    "for sentence in summary:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1b09a4",
   "metadata": {},
   "source": [
    "# 8. Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63407837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤ Speak something...\n",
      "ðŸ“ You said: yaar Aruna is there\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Initialize recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Use microphone\n",
    "with sr.Microphone() as source:\n",
    "    print(\"ðŸŽ¤ Speak something...\")\n",
    "    audio = recognizer.listen(source)\n",
    "\n",
    "    try:\n",
    "        # Recognize speech using Google Web API\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(\"ðŸ“ You said:\", text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"âŒ Could not understand audio\")\n",
    "    except sr.RequestError:\n",
    "        print(\"âš ï¸ Could not request results; check your internet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a115ce3c",
   "metadata": {},
   "source": [
    "# 9. Autocorrect and Spell Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f0441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Ths is smple txt for autocorect\n",
      "After : The is smile txt for autocorect\n",
      "\n",
      "Before: I hav a dreem\n",
      "After : I had a dream\n",
      "\n",
      "Before: Pythn is a grate progrmming langauge\n",
      "After : Myth is a grate programming language\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Example sentence with spelling mistakes\n",
    "texts = [\n",
    "    \"Ths is smple txt for autocorect\",\n",
    "    \"I hav a dreem\",\n",
    "    \"Pythn is a grate progrmming langauge\"\n",
    "]\n",
    "\n",
    "for i in texts:\n",
    "    # Create a TextBlob object\n",
    "    blob = TextBlob(i)\n",
    "\n",
    "    # Apply autocorrect\n",
    "    corrected = blob.correct()\n",
    "\n",
    "    print(\"Before:\", i)\n",
    "    print(\"After :\", corrected)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e012deee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Ths is smple txt for autocorect\n",
      "After : The is simple txt for autocorect\n",
      "\n",
      "Before: I hav a dreem\n",
      "After : I hav a dream\n",
      "\n",
      "Before: Pythn is a grate progrmming langauge\n",
      "After : Python is a rate programming language\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller(lang='en')\n",
    "\n",
    "texts = [\n",
    "    \"Ths is smple txt for autocorect\",\n",
    "    \"I hav a dreem\",\n",
    "    \"Pythn is a grate progrmming langauge\"\n",
    "]\n",
    "\n",
    "# Apply autocorrect\n",
    "for t in texts:\n",
    "    corrected = spell(t)\n",
    "    print(\"Before:\", t)\n",
    "    print(\"After :\", corrected)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1aa3d8",
   "metadata": {},
   "source": [
    "# 10. Information Retrieval (Search Engines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "014ed6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.47 | Doc: Python is great for data science\n",
      "Score: 0.21 | Doc: Data science uses Python and R\n",
      "Score: 0.08 | Doc: Machine learning is a part of artificial intelligence\n",
      "Score: 0.00 | Doc: Cooking recipes with lots of ingredients\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Example documents\n",
    "docs = [\n",
    "    \"Python is great for data science\",\n",
    "    \"Machine learning is a part of artificial intelligence\",\n",
    "    \"Data science uses Python and R\",\n",
    "    \"Cooking recipes with lots of ingredients\"\n",
    "]\n",
    "\n",
    "# User query\n",
    "query = \"Which language is best for data science?\"\n",
    "\n",
    "# Add query to the document list\n",
    "documents = docs + [query]\n",
    "\n",
    "# Vectorize using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Compute cosine similarity between query and all documents\n",
    "cosine_sim = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
    "\n",
    "# Show ranked results\n",
    "for idx in cosine_sim[0].argsort()[::-1]:\n",
    "    print(f\"Score: {cosine_sim[0][idx]:.2f} | Doc: {docs[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a230465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.datacamp.com/blog/top-python-libraries-for-data-science\n",
      "https://www.datacamp.com/blog/top-python-libraries-for-data-science#introduction-pytho\n",
      "https://www.datacamp.com/blog/top-python-libraries-for-data-science#6.-scikit-learn-thete\n",
      "https://www.datacamp.com/blog/top-python-libraries-for-data-science#11.-rapids.ai-cudf-and-cuml-thera\n",
      "https://www.datacamp.com/blog/top-python-libraries-for-data-science#15.-tpot-tpoti\n"
     ]
    }
   ],
   "source": [
    "from googlesearch import search\n",
    "\n",
    "query = \"Best Python libraries for data science\"\n",
    "\n",
    "# Perform Google Search\n",
    "#for result in search(query, num_results=5):\n",
    "\n",
    "#query = \"Best Python libraries for data science\"\n",
    "\n",
    "# Get top 5 search results\n",
    "results = search(query, num=5, stop=5, pause=2)\n",
    "\n",
    "for link in results:\n",
    "    print(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb825836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.datacamp.com/blog/top-python-libraries-for-data-science\n",
      "https://www.datacamp.com/blog/top-python-libraries-for-data-science#introduction-pytho\n",
      "https://www.datacamp.com/blog/top-python-libraries-for-data-science#6.-scikit-learn-thete\n",
      "https://www.datacamp.com/blog/top-python-libraries-for-data-science#11.-rapids.ai-cudf-and-cuml-thera\n",
      "https://www.datacamp.com/blog/top-python-libraries-for-data-science#15.-tpot-tpoti\n"
     ]
    }
   ],
   "source": [
    "from googlesearch import search\n",
    "query = \"Best Python libraries for data science\"\n",
    "results = search(query, stop=5)\n",
    "for link in results:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e954a46",
   "metadata": {},
   "source": [
    "# 11. Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51332d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: This is an English sentence.\n",
      "Detected Language: en\n",
      "\n",
      "Text: C'est une phrase franÃ§aise.\n",
      "Detected Language: fr\n",
      "\n",
      "Text: à¤¯à¤¹ à¤à¤• à¤¹à¤¿à¤‚à¤¦à¥€ à¤µà¤¾à¤•à¥à¤¯ à¤¹à¥ˆà¥¤\n",
      "Detected Language: hi\n",
      "\n",
      "Text: Dies ist ein deutscher Satz.\n",
      "Detected Language: de\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect, detect_langs\n",
    "\n",
    "# Sample texts\n",
    "texts = [\n",
    "    \"This is an English sentence.\",\n",
    "    \"C'est une phrase franÃ§aise.\",\n",
    "    \"à¤¯à¤¹ à¤à¤• à¤¹à¤¿à¤‚à¤¦à¥€ à¤µà¤¾à¤•à¥à¤¯ à¤¹à¥ˆà¥¤\",\n",
    "    \"Dies ist ein deutscher Satz.\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    lang = detect(text)\n",
    "    print(f\"Text: {text}\\nDetected Language: {lang}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf28ae",
   "metadata": {},
   "source": [
    "# 12. Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b54ab7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from rake_nltk import Rake\\n\\n# Initialize RAKE\\nrake = Rake()\\n\\n# Text input\\ntext = \"Natural Language Processing helps computers understand human language. Keyword extraction is useful for summarizing long documents.\"\\n\\n# Extract keywords\\nrake.extract_keywords_from_text(text)\\n\\n# Get top keywords\\nkeywords = rake.get_ranked_phrases()\\nprint(\"Extracted Keywords:\")\\nfor kw in keywords:\\n    print(\"-\", kw)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from rake_nltk import Rake\n",
    "\n",
    "# Initialize RAKE\n",
    "rake = Rake()\n",
    "\n",
    "# Text input\n",
    "text = \"Natural Language Processing helps computers understand human language. Keyword extraction is useful for summarizing long documents.\"\n",
    "\n",
    "# Extract keywords\n",
    "rake.extract_keywords_from_text(text)\n",
    "\n",
    "# Get top keywords\n",
    "keywords = rake.get_ranked_phrases()\n",
    "print(\"Extracted Keywords:\")\n",
    "for kw in keywords:\n",
    "    print(\"-\", kw)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df6bcc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Keywords:\n",
      "- natural language processing helps computers understand human language\n",
      "- summarizing long documents\n",
      "- keyword extraction\n",
      "- useful\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "\n",
    "# Initialize RAKE\n",
    "rake = Rake()\n",
    "\n",
    "# Text input\n",
    "text = \"Natural Language Processing helps computers understand human language. Keyword extraction is useful for summarizing long documents.\"\n",
    "\n",
    "# Extract keywords\n",
    "rake.extract_keywords_from_text(text)\n",
    "\n",
    "# Get top keywords\n",
    "keywords = rake.get_ranked_phrases()\n",
    "\n",
    "print(\"Extracted Keywords:\")\n",
    "for kw in keywords:\n",
    "    print(\"-\", kw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c40d87e",
   "metadata": {},
   "source": [
    "# 13. Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6000ff48",
   "metadata": {},
   "source": [
    "# 14. Text-to-Speech (TTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44450267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "# Initialize the TTS engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Set properties like rate, volume, and voice\n",
    "engine.setProperty('rate', 150)  # Speed of speech\n",
    "engine.setProperty('volume', 1)  # Volume (0.0 to 1.0)\n",
    "\n",
    "# Say something\n",
    "engine.say(\"Hello, I am a text to speech system.\")\n",
    "engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Capture speech from microphone\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Listening...\")\n",
    "    audio = recognizer.listen(source)\n",
    "\n",
    "# Recognize speech\n",
    "try:\n",
    "    text = recognizer.recognize_google(audio)\n",
    "    print(\"You said: \", text)\n",
    "\n",
    "    # Respond with TTS\n",
    "    engine.say(f\"You said: {text}\")\n",
    "    engine.runAndWait()\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sorry, I couldn't understand.\")\n",
    "    engine.say(\"Sorry, I couldn't understand.\")\n",
    "    engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "voices = engine.getProperty('voices')\n",
    "for voice in voices:\n",
    "    print(f\"ID: {voice.id}, Name: {voice.name}\")\n",
    "# Set a specific voice\n",
    "engine.setProperty('voice', voices[1].id)  # Choosing second voice (female)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e84db4",
   "metadata": {},
   "source": [
    "# 15. Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d921fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from transformers import pipeline\\n\\n# Load QA pipeline\\nqa_pipeline = pipeline(\"question-answering\")\\n\\n# Input text and question\\ncontext = \"Natural Language Processing enables machines to understand and interpret human language.\"\\nquestion = \"What does NLP enable machines to do?\"\\n\\n# Get answer\\nresult = qa_pipeline(question=question, context=context)\\nprint(result)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from transformers import pipeline\n",
    "\n",
    "# Load QA pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\")\n",
    "\n",
    "# Input text and question\n",
    "context = \"Natural Language Processing enables machines to understand and interpret human language.\"\n",
    "question = \"What does NLP enable machines to do?\"\n",
    "\n",
    "# Get answer\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "print(result)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d09426c",
   "metadata": {},
   "source": [
    "# 16. Text Similarity / Duplicate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ae8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def jaccard_similarity(str1, str2):\n",
    "    a = set(str1.lower().split())\n",
    "    b = set(str2.lower().split())\n",
    "    return len(a & b) / len(a | b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7667b0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15064018]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "texts = [\"NLP is fun\", \"Natural Language Processing is enjoyable\"]\n",
    "vec = TfidfVectorizer().fit_transform(texts)\n",
    "similarity = cosine_similarity(vec[0:1], vec[1:2])\n",
    "print(similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b62d015a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sentence_transformers import SentenceTransformer, util\\n\\nmodel = SentenceTransformer(\\'all-MiniLM-L6-v2\\')\\nemb1 = model.encode(\"NLP is fun\", convert_to_tensor=True)\\nemb2 = model.encode(\"Natural Language Processing is enjoyable\", convert_to_tensor=True)\\n\\nsimilarity = util.pytorch_cos_sim(emb1, emb2)\\nprint(similarity)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "emb1 = model.encode(\"NLP is fun\", convert_to_tensor=True)\n",
    "emb2 = model.encode(\"Natural Language Processing is enjoyable\", convert_to_tensor=True)\n",
    "\n",
    "similarity = util.pytorch_cos_sim(emb1, emb2)\n",
    "print(similarity)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d98c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Pair:\n",
      " - What is NLP?\n",
      " - What is NLP?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'text': [\"What is NLP?\", \"Define Natural Language Processing\", \"Explain AI\", \"What is NLP?\"]\n",
    "})\n",
    "\n",
    "tfidf = TfidfVectorizer().fit_transform(df['text'])\n",
    "cos_sim = cosine_similarity(tfidf)\n",
    "\n",
    "# Print pairs with high similarity (excluding diagonal)\n",
    "for i in range(len(df)):\n",
    "    for j in range(i+1, len(df)):\n",
    "        if cos_sim[i][j] > 0.8:\n",
    "            print(f\"Duplicate Pair:\\n - {df['text'][i]}\\n - {df['text'][j]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70935651",
   "metadata": {},
   "source": [
    "# 17. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac5b99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: ['Natural', 'Language', 'Processing', 'is', 'fun', '.', 'Let', \"'s\", 'explore', 'it', '!']\n",
      "Sentences: ['Natural Language Processing is fun.', \"Let's explore it!\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "text = \"Natural Language Processing is fun. Let's explore it!\"\n",
    "print(\"Words:\", word_tokenize(text))\n",
    "print(\"Sentences:\", sent_tokenize(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3370b74d",
   "metadata": {},
   "source": [
    "# 18.  Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "509dcab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "fli\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem(\"running\"))  # Output: run\n",
    "print(stemmer.stem(\"flies\"))    # Output: fli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9b822",
   "metadata": {},
   "source": [
    "# 19. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd5218b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"running\", pos='v'))  # Output: run\n",
    "print(lemmatizer.lemmatize(\"better\", pos='a'))   # Output: good\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e49925",
   "metadata": {},
   "source": [
    "# 20. Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db74a5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello there!', 'How are you doing?', 'NLP is interesting.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = \"Hello there! How are you doing? NLP is interesting.\"\n",
    "print(sent_tokenize(text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
